<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>一个python爬虫 | liubaojie's site</title>
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <link rel="stylesheet" href="/css/default.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile.css" type="text/css" />
  <link rel="shortcut icon" href="/css/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/css/favicon.ico" mce_href="/favicon.ico" type="image/x-icon">
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>

<body>
  <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
  html {
    background: #333333;
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
  }
  @media screen and (max-width: 750px){
    body { background: rgba(255, 255, 255, 0.9); }
  }
</style>

<div id="content" class="post" style="margin-top: 20px;">
  <div id="avatar" class="avatar circle" data-in-right="false" style="width: 150px; height: 150px; position: fixed; top: 40px; z-index: 99; opacity: 0;">
    <div class="center" style="margin-top: 4px; height: 142px; width: 142px; border-radius: 71px; background-image: url('../images/user.png');"></div>
  </div>

  <div class="entry" style="position: relative;">
    <h1 class="entry-title"><a href="/a-python-screw" title="一个python爬虫">一个python爬虫</a></h1>

    <p class="entry-date">2016-05-14 
        <span class="lastModified" style="display: none;" data-source="_posts/python&R/2016-05-14-a-python-screw.md">最后更新时间: 
        </span>
    </p>


    <p>写论文需要数据，但是和讯网并没有提供数据的下载，所以就想着自己写个爬虫，一来看看自己能不能搞定这个爬虫，二来可以拿到数据。<br>
话不多说，先来理下思路：</p>

<h2>思路</h2>

<p><img src="http://liubj2016.github.io/Akuan/group/python&amp;R/images/1.png" alt="image"></p>

<p>这里面有261只债券，总共6页。最开始我是准备就爬这个页面的，但是发现提供的数据不够，点进去一只：</p>

<p><img src="http://liubj2016.github.io/Akuan/group/python&amp;R/images/2.png" alt="image"></p>

<p>这才是我想要的。<br>
所以现在就有了一个大致的思路：<br>
1. 先爬第一个网页，取得所有城投债的链接；
2. 再解析每个网页，取得数据。</p>

<h2>获得链接</h2>

<p>打开网页，右键&gt;检查：</p>

<p><img src="http://liubj2016.github.io/Akuan/group/python&amp;R/images/3.png" alt="image"></p>

<p>链接就藏在a标签里面了，下面是代码：</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_lianjie</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="c">#定义一个函数</span>
    <span class="n">page_source</span><span class="o">=</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
    <span class="n">bs_source</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page_source</span><span class="p">,</span><span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">bs_source2</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bs_source</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)),</span><span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">report_text</span><span class="o">=</span><span class="n">bs_source2</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span><span class="n">href</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c">#用beautifulsoup解析网页</span>
    <span class="n">lianjie</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">report_text</span><span class="p">:</span>
        <span class="n">lianjie</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="s">'href'</span><span class="p">])</span>

    <span class="n">lianjie</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">lianjie</span><span class="p">))</span>
    <span class="c">#去掉重复的</span>
    <span class="k">return</span> <span class="n">lianjie</span>
</code></pre></div>
<h2>获取表</h2>

<p>接下来就是要获取每个链接里的数据了，还是要先分析网页，找到需要的数据在哪里，<br>
代码如下：</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_biao</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">http</span><span class="o">=</span><span class="n">urllib3</span><span class="o">.</span><span class="n">PoolManager</span><span class="p">()</span>
    <span class="c">#不用这个好像网页会加载不完全，具体什么意思我也不懂。。</span>
    <span class="n">page_source</span><span class="o">=</span><span class="n">http</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="s">'GET'</span><span class="p">,</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page_source</span><span class="p">,</span><span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'tr'</span><span class="p">,</span><span class="n">align</span><span class="o">=</span><span class="s">"center"</span><span class="p">)</span>
    <span class="n">soup2</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">),</span><span class="s">'lxml'</span> <span class="p">)</span>
    <span class="n">a</span><span class="o">=</span><span class="n">soup2</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>
    <span class="c">#还是用beautifulsoup包解析网页</span>

    <span class="c">#然后将获取的数据做成dataframe</span>
    <span class="n">index</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">iterm</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">2</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'unicode_escape'</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">iterm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'unicode_escape'</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

    <span class="n">biao</span><span class="o">=</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iterm</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">biao</span>
</code></pre></div>
<h2>合并数据</h2>

<p>到这一步就很简单了，因为表都是DataFrame格式，代码如下：</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">biao</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'data.csv'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'gbk'</span><span class="p">)</span><span class="c">#注意编码，不然会乱码</span>
</code></pre></div>
<p>至此这个爬虫就差不多完成了，但是有个问题，就是：很！慢！<br>
我点击运行，过了十几分钟才出结果，所以得用多线程优化一下，<br>
下面是完整代码：</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">urllib3</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">threading</span>
<span class="c">#加载所要用的包</span>

<span class="k">def</span> <span class="nf">get_lianjie</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">page_source</span><span class="o">=</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
    <span class="n">bs_source</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page_source</span><span class="p">,</span><span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">bs_source2</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bs_source</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)),</span><span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">report_text</span><span class="o">=</span><span class="n">bs_source2</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span><span class="n">href</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">lianjie</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">report_text</span><span class="p">:</span>
        <span class="n">lianjie</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="s">'href'</span><span class="p">])</span>

    <span class="n">lianjie</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">lianjie</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">lianjie</span>

<span class="k">def</span> <span class="nf">get_biao</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">http</span><span class="o">=</span><span class="n">urllib3</span><span class="o">.</span><span class="n">PoolManager</span><span class="p">()</span>
    <span class="n">page_source</span><span class="o">=</span><span class="n">http</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="s">'GET'</span><span class="p">,</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page_source</span><span class="p">,</span><span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'tr'</span><span class="p">,</span><span class="n">align</span><span class="o">=</span><span class="s">"center"</span><span class="p">)</span>
    <span class="n">soup2</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">),</span><span class="s">'lxml'</span> <span class="p">)</span>
    <span class="n">a</span><span class="o">=</span><span class="n">soup2</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>

    <span class="n">index</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">iterm</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">2</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'unicode_escape'</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">iterm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'unicode_escape'</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

    <span class="n">biao</span><span class="o">=</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iterm</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">biao</span>

<span class="c">#获取全部261个链接</span>
<span class="n">lianjie</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">):</span>
    <span class="n">url</span><span class="o">=</span> <span class="s">'http://so.hexun.com/list.do?type=ALL&amp;stype=BOND&amp;key=</span><span class="si">%</span><span class="s">B3</span><span class="si">%</span><span class="s">C7</span><span class="si">%</span><span class="s">CD</span><span class="si">%</span><span class="s">B6</span><span class="si">%</span><span class="s">D5</span><span class="si">%</span><span class="s">AE&amp;page={0:d}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="n">page_lianjie</span><span class="o">=</span><span class="n">get_lianjie</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">lianjie</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">page_lianjie</span><span class="p">)</span>

<span class="c">#获取所有的表</span>
<span class="n">biao</span><span class="o">=</span><span class="p">[]</span>
<span class="k">def</span> <span class="nf">one</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">page_biao</span> <span class="o">=</span> <span class="n">get_biao</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">biao</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">page_biao</span><span class="p">)</span>
    <span class="k">return</span>

<span class="c">#多线程    </span>
<span class="n">threadlist</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">lianjie</span><span class="p">:</span>
    <span class="n">t</span><span class="o">=</span><span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">one</span><span class="p">,</span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">url</span><span class="p">,))</span>
    <span class="n">t</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">threadlist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">threadlist</span><span class="p">:</span>
    <span class="n">t</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="c">#最后导出数据</span>
<span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">biao</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'data.csv'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'gbk'</span><span class="p">)</span>
</code></pre></div>
<p>最终效果：</p>

<p><img src="http://liubj2016.github.io/Akuan/group/python&amp;R/images/4.png" alt="image"></p>



  </div>


  <div id="menuIndex" class="sidenav">
    <div class="myinfo"><center>
      <div id="avatarHolder" class="avatar circle" style="width: 0px; height: 0px; box-shadow: none; margin-bottom: 20px;"></div>
      <a href="/index.html" title="Homepage"><i class="icon-home icon-large"></i> Home</a>
      <a href="http://www.linkedin.com/in"><i class="icon-linkedin-sign icon-large"></i> Profile</a>
      <a href="https://github.com/"><i class="icon-github icon-large"></i> Code</a>
      <a href="mailto:liubaojie2016@163.com"><i class="icon-envelope icon-large"></i> Mail</a>
    </center></div>
    <div id="menu"></div>
  </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>

</body>


</html>
